import os
import glob
import numpy as np
import concurrent.futures
import time
import re
from openai import OpenAI
from sklearn.metrics.pairwise import cosine_similarity

# ================= é…ç½®åŒºåŸŸ =================
# æ•…äº‹æ ¹ç›®å½•
DATA_ROOT = "batch_stories_ablation3_2"
# å¹¶å‘çº¿ç¨‹æ•° (ç”¨äº GPT-4o æ¦‚å¿µæå–)
MAX_WORKERS = 20
# Embedding æ¨¡å‹
EMBEDDING_MODEL = "text-embedding-3-small"
# ===========================================


client = OpenAI()

def get_theme_from_folder(folder_name):
    """ä»æ–‡ä»¶å¤¹åæå–ä¸»é¢˜ï¼Œä¾‹å¦‚ 'Shoes_A3_I3' -> 'Shoes'"""
    cleaned = re.sub(r'_A\d+_I\d+$', '', folder_name)
    return cleaned.replace('_', ' ')

def read_all_stories(root_dir):
    """æ‰«ææ‰€æœ‰å­æ–‡ä»¶å¤¹ï¼ŒæŒ‰æ–‡ä»¶å¤¹åˆ†ç»„è¯»å–æ•…äº‹"""
    groups = {}
    
    if not os.path.exists(root_dir):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°ç›®å½• {root_dir}")
        return {}

    print(f"ğŸ“‚ æ­£åœ¨æ‰«æ {root_dir} ...")
    
    for subdir, _, files in os.walk(root_dir):
        if subdir == root_dir:
            continue
            
        folder_name = os.path.basename(subdir)
        txt_files = [f for f in files if f.endswith(".txt") and not f.startswith(".")]
        
        if not txt_files:
            continue
            
        story_list = []
        for f in txt_files:
            path = os.path.join(subdir, f)
            with open(path, 'r', encoding='utf-8') as file:
                content = file.read().strip()
                if content:
                    story_list.append({"filename": f, "content": content, "path": path})
        
        if story_list:
            groups[folder_name] = story_list
            
    return groups

def extract_single_concept(story_data, theme):
    """
    æå–å•ä¸ªæ•…äº‹çš„æ ¸å¿ƒæ¦‚å¿µ
    """
    try:
        # å¦‚æœå†…å®¹å¤ªçŸ­ï¼Œå¯èƒ½æ— æ•ˆ
        if len(story_data['content']) < 50:
            return None

        prompt = f"""
        You are a researcher analyzing sci-fi stories.
        The following is a story based on the theme: "{theme}".
        
        Task: Identify the specific futuristic evolution, function, or form of the "{theme}" described in this story.
        
        Constraint: Summarize the concept in NO MORE THAN 5 words. English Only.
        Focus on the functionality and social role. 
        Do NOT summarize the plot. Only summarize the object's setting.
        
        Story content:
        {story_data['content'][:2000]} 
        """
        
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are a concise summarizer."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1
        )
        concept = response.choices[0].message.content.strip()
        return concept
    except Exception as e:
        print(f"  [æå–å¤±è´¥] {story_data['filename']}: {e}")
        return None

def process_group_concepts(folder_name, stories):
    """
    å¤„ç†ä¸€ä¸ªç»„ï¼ˆæ–‡ä»¶å¤¹ï¼‰å†…çš„æ‰€æœ‰æ•…äº‹ï¼šå¹¶å‘æå–æ¦‚å¿µ
    """
    theme = get_theme_from_folder(folder_name)
    print(f"\nğŸ” å¤„ç†åˆ†ç»„: [{folder_name}] (ä¸»é¢˜: {theme}, æ•°é‡: {len(stories)})")
    
    concepts = []
    filenames = []
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_story = {
            executor.submit(extract_single_concept, story, theme): story 
            for story in stories
        }
        
        completed = 0
        total = len(stories)
        
        for future in concurrent.futures.as_completed(future_to_story):
            story = future_to_story[future]
            result = future.result()
            
            if result:
                concepts.append(result)
                filenames.append(story['filename'])
            
            completed += 1
            if completed % 20 == 0:
                print(f"  ...è¿›åº¦ {completed}/{total}")

    return concepts, filenames

def get_embeddings_batch(text_list, batch_size=50):
    """
    æ‰¹é‡è·å– Embeddings ä»¥èŠ‚çœè¯·æ±‚æ¬¡æ•°
    """
    all_embeddings = []
    for i in range(0, len(text_list), batch_size):
        batch = text_list[i : i + batch_size]
        try:
            response = client.embeddings.create(
                input=batch,
                model=EMBEDDING_MODEL
            )
            # ä¿è¯é¡ºåºä¸€è‡´
            batch_embeddings = [data.embedding for data in response.data]
            all_embeddings.extend(batch_embeddings)
        except Exception as e:
            print(f"  [Embedding Error] Batch {i}: {e}")
            # å¦‚æœå¤±è´¥ï¼Œå¡«å……é›¶å‘é‡é˜²æ­¢å´©æºƒï¼ˆæˆ–è€…é‡è¯•ï¼‰
            all_embeddings.extend([[0.0]*1536] * len(batch))
            
    return all_embeddings

def calculate_diversity_score(embeddings):
    """
    è®¡ç®—å¤šæ ·æ€§åˆ†æ•° (1 - å¹³å‡ä½™å¼¦ç›¸ä¼¼åº¦)
    """
    if len(embeddings) < 2:
        return 0.0, np.array([])
        
    matrix = cosine_similarity(embeddings)
    n = len(matrix)
    
    # å–ä¸Šä¸‰è§’ï¼ˆä¸å«å¯¹è§’çº¿ï¼‰
    upper_triangle_indices = np.triu_indices(n, k=1)
    similarities = matrix[upper_triangle_indices]
    
    if len(similarities) == 0:
        return 0.0, matrix

    avg_similarity = np.mean(similarities)
    diversity_score = 1 - avg_similarity
    
    return diversity_score, matrix

def main():
    start_time = time.time()
    
    # 1. è¯»å–æ‰€æœ‰æ•…äº‹
    groups = read_all_stories(DATA_ROOT)
    if not groups:
        print("æœªæ‰¾åˆ°ä»»ä½•æ•…äº‹æ–‡ä»¶ã€‚")
        return

    report_data = []

    # 2. é€ç»„å¤„ç†
    for folder_name, stories in groups.items():
        # A. æå–æ¦‚å¿µ
        concepts, filenames = process_group_concepts(folder_name, stories)
        
        if len(concepts) < 2:
            print(f"  âš ï¸ è·³è¿‡ {folder_name}: æœ‰æ•ˆæ¦‚å¿µå°‘äº 2 ä¸ª")
            continue
            
        # B. è·å–å‘é‡
        print(f"  ğŸ§¬ è®¡ç®— Embeddings ({len(concepts)} ä¸ªæ¦‚å¿µ)...")
        embeddings = get_embeddings_batch(concepts)
        
        # C. è®¡ç®—å¤šæ ·æ€§
        diversity, matrix = calculate_diversity_score(embeddings)
        
        print(f"  âœ… å¤šæ ·æ€§å¾—åˆ†: {diversity:.4f}")
        
        report_data.append({
            "folder": folder_name,
            "count": len(concepts),
            "diversity": diversity,
            "concepts": concepts,
            "filenames": filenames,
            "matrix": matrix
        })

    # 3. è¾“å‡ºæœ€ç»ˆæŠ¥å‘Š
    print("\n" + "="*60)
    print("ğŸ“Š æ¦‚å¿µå¤šæ ·æ€§åˆ†ææŠ¥å‘Š (Concept Diversity Report)")
    print("="*60)
    print(f"{'Folder / Theme':<30} | {'Count':<6} | {'Diversity Score':<15}")
    print("-" * 60)
    
    total_diversity = 0
    valid_groups = 0
    
    for item in report_data:
        print(f"{item['folder']:<30} | {item['count']:<6} | {item['diversity']:.4f}")
        total_diversity += item['diversity']
        valid_groups += 1
        
    print("-" * 60)
    if valid_groups > 0:
        print(f"{'AVERAGE':<30} | {'-':<6} | {total_diversity/valid_groups:.4f}")
    
    # 4. ä¿å­˜è¯¦ç»†ç»“æœåˆ° CSV
    with open("diversity_results.csv", "w", encoding="utf-8") as f:
        f.write("Folder,Filename,Extracted_Concept\n")
        for item in report_data:
            for fname, concept in zip(item['filenames'], item['concepts']):
                # å¤„ç†ä¸€ä¸‹ concept é‡Œçš„é€—å·æˆ–æ¢è¡Œï¼Œé˜²æ­¢ CSV æ ¼å¼ä¹±æ‰
                clean_concept = concept.replace('"', "'").replace('\n', ' ')
                f.write(f"{item['folder']},{fname},\"{clean_concept}\"\n")
                
    print(f"\nè¯¦ç»†æ¦‚å¿µæå–ç»“æœå·²ä¿å­˜è‡³ diversity_results.csv")
    print(f"æ€»è€—æ—¶: {time.time() - start_time:.2f} ç§’")

if __name__ == "__main__":
    main()